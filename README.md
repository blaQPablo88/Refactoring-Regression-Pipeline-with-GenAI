# Refactoring Regression Pipeline with GenAI

Refactoring my [First Pipeline](https://github.com/blaQPablo88/First_Pipeline_Python) project using GenAI engineering principles to improve modularity, readability, and performance.

---

---

## ğŸ™ Acknowledgements

This project is inspired by and based on the work by [Yash Sahu](https://www.kaggle.com/code/yashsahu02/drw-crypto-market-prediction) on Kaggle.

Credit to the original author for the initial data exploration, model experimentation, and notebook structure.

This refactor focuses on improving modularity, maintainability, and scalability using GenAI best practices.

## ğŸ“¦ Installation Guide

### âœ… Required Libraries

Install the following modules using `pip` (run in terminal or inside your virtual environment):

```bash
pip install numpy pandas matplotlib seaborn scikit-learn xgboost lightgbm catboost pyarrow kaggle
```

> âš ï¸ Make sure you install all dependencies **before running the scripts**.

---

### âœ… System-Level Installation

**Numpy (System Install)**  
Refer to [numpy.org/install](https://numpy.org/install)

- **Windows:**
  ```bash
  choco install numpy
  ```

- **Linux:**
  ```bash
  sudo apt install python3-numpy
  ```

> Test numpy install:
```python
import numpy as np
print(np.__version__)
```

---

## ğŸ§¾ Whatâ€™s a `.parquet` File?

A `.parquet` file is a highly efficient, column-based storage format used in big data environments.

### ğŸ” Why Use Parquet?
- **Columnar Format:** Optimized for analytics and queries
- **Efficient Compression:** Smaller file sizes than CSV
- **Schema-aware:** Retains data types and structure
- **Performance:** Faster reading when you only need some columns

Used heavily with tools like Pandas, PyArrow, Spark, and in ML workflows.

---

## ğŸ“ Project Structure

```
crypto-regression/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ kaggle/                # Raw input data from Kaggle
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ saved_predictions/     # Output predictions by model
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_loader.py         # Handles data import and preprocessing
â”‚   â”œâ”€â”€ preprocessing.py       # Data cleaning and transformation
â”‚   â”œâ”€â”€ feature_selection.py   # SelectKBest or other techniques
â”‚   â”œâ”€â”€ train_models.py        # Train & evaluate models
â”‚   â””â”€â”€ utils.py               # Metrics, evaluation, helper functions
â”‚
â”œâ”€â”€ main.py                    # Main orchestration script
â””â”€â”€ README.md                  # You are here ğŸ“˜
```

---

## ğŸ“¥ Data Access

Make sure you have Kaggle CLI configured and authenticated, then download the dataset:

```bash
pip install kaggle
kaggle datasets download -d yashsahu02/drw-crypto-market-prediction
```

---

## ğŸš€ Running the Project

Once dependencies are installed and data is in place:

```bash
python main.py
```

This will:
- Load the dataset
- Clean and preprocess the data
- Select features
- Train models (e.g., Linear Regression, XGBoost)
- Save predictions for submission

---

## ğŸ“Š Outputs

- Model evaluation metrics printed in console
- `.csv` prediction files per model (saved in `models/saved_predictions/`)
- `model_performance_summary.csv` for comparison of algorithms

---

## ğŸ§  Powered by GenAI Refactor Principles

This project demonstrates how AI-assisted refactoring can improve a raw ML script into a clean, modular, maintainable pipeline.

---

## ğŸ“Œ To-Do (Next Steps)
- [ ] Add more regression models
- [ ] Integrate logging instead of print statements
- [ ] Unit tests for data loading and evaluation
- [ ] Deploy via Streamlit or FastAPI

---

Created with â¤ï¸ by Kagiso using GenAI.